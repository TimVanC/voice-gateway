# Railway Production Cutover - Summary

## ‚úÖ Completed Tasks

### 1. Configuration System
- ‚úÖ Created `src/config/baseUrl.js`
  - Dynamic URL handling: `PUBLIC_BASE_URL` (prod) vs `LOCAL_PUBLIC_BASE_URL` (dev)
  - Automatic environment detection via `NODE_ENV`
  - URL validation

### 2. Server Hardening
- ‚úÖ All 3 servers bind to `0.0.0.0` (Railway requirement)
- ‚úÖ Production timeouts added:
  - `keepAliveTimeout: 70s`
  - `headersTimeout: 75s`
- ‚úÖ Health endpoint standardized: `{status: "ok", timestamp: "..."}`

### 3. Structured Latency Logs
Added timing metrics in `server-hybrid.js`:
- ‚è±Ô∏è Webhook ‚Üí OpenAI connection
- ‚è±Ô∏è Session ready time
- ‚è±Ô∏è First LLM token latency
- ‚è±Ô∏è First TTS audio chunk latency

### 4. PII Masking
- ‚úÖ Phone numbers masked in logs: `973***2528`
- ‚úÖ No API keys in logs

### 5. Docker Support
- ‚úÖ Created `Dockerfile`:
  - Node 20 Alpine base
  - FFmpeg pre-installed for audio processing
  - Health check endpoint
  - Defaults to `server-hybrid.js`

### 6. Documentation
- ‚úÖ Created `DEPLOYMENT.md`:
  - Railway environment variables
  - Twilio webhook configuration
  - Railway commands (`railway logs -f`, deploy, rollback, region change)
  - Local development setup with ngrok
  - Monitoring and troubleshooting

### 7. Updated All Servers
- ‚úÖ `src/server-hybrid.js` - Production default (OpenAI + ElevenLabs)
- ‚úÖ `src/server-realtime.js` - Full duplex mode
- ‚úÖ `src/server.js` - Legacy mode

### 8. Package Configuration
- ‚úÖ Updated `package.json`:
  - `npm start` now runs `server-hybrid.js` (production default)
  - All dev scripts preserved

## üöÄ Deployment Steps

### Quick Deploy to Railway

```bash
# 1. Create PR and merge to main
git checkout main
git merge chore/railway-prod-cutover
git push origin main

# 2. Railway auto-deploys from main
# Watch logs:
railway logs -f
```

### Required Railway Environment Variables

```bash
NODE_ENV=production
PUBLIC_BASE_URL=https://voice-gateway-production-187c.up.railway.app
OPENAI_API_KEY=sk-proj-...
ELEVENLABS_API_KEY=...
ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM
```

### Update Twilio Webhook

Point your Twilio phone number to:
```
https://voice-gateway-production-187c.up.railway.app/twilio/voice
```

## ‚úÖ Post-Deploy Checklist

- [ ] `GET /health` returns `200 OK`
- [ ] Test call connects
- [ ] Logs show:
  - [ ] Webhook received
  - [ ] OpenAI session opened
  - [ ] First LLM token timing
  - [ ] First TTS audio timing
- [ ] Call quality is good
- [ ] No crashes or errors

## üîç Monitoring

### Expected Log Flow

```
üìû Incoming call to /twilio/voice
From: 973***2528
‚è±Ô∏è  Webhook processed in 45ms

üìû New Twilio connection from: <IP>
üîå Connecting to OpenAI Realtime API...
‚úÖ Connected to OpenAI Realtime API
‚è±Ô∏è  Webhook ‚Üí OpenAI connection: 450ms

üéØ OpenAI session created: sess_...
‚è±Ô∏è  Session ready in 120ms

‚è±Ô∏è  First LLM token: 380ms
‚è±Ô∏è  First TTS audio chunk: 520ms

üéôÔ∏è AI: Hi there! Thanks for calling...
```

### Troubleshooting

**No audio:**
- Check Twilio webhook URL
- Verify WebSocket path: `/hybrid/twilio`

**500 errors:**
- Check Railway logs: `railway logs -f`
- Verify environment variables are set

**Slow responses:**
- Check latency metrics in logs
- Consider region change (Railway dashboard)

## üì¶ Files Changed

```
New:
  DEPLOYMENT.md
  Dockerfile
  src/config/baseUrl.js

Modified:
  package.json           - Default start script
  src/server-hybrid.js   - BASE_URL, timeouts, latency logs
  src/server-realtime.js - BASE_URL, timeouts
  src/server.js          - BASE_URL, timeouts
```

## üéâ Benefits

1. **Production Ready**: Proper timeouts, health checks, error handling
2. **Observability**: Structured latency logs for debugging
3. **Security**: PII masking in logs
4. **Developer Experience**: Easy local dev with ngrok
5. **Auto Deploy**: Railway detects main branch changes
6. **Zero Downtime**: Railway handles blue/green deployments
7. **Flexibility**: Easy region switching, rollbacks

## üìö Next Steps

After merging and deploying:
1. Test the production endpoint
2. Monitor first few calls closely
3. Tune latency based on logs
4. Optional: Add custom domain
5. Optional: Add autoscaling rules

